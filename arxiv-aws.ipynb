{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae977bc3-d3cf-4492-a359-a95f8156fb52",
   "metadata": {},
   "source": [
    "# arXiv Matplotlib Query\n",
    "\n",
    "Anecdotally the Matplotlib maintainers were told \n",
    "\n",
    "*\"About 15% of arXiv papers use Matplotlib\"*\n",
    "\n",
    "Unfortunately the original analysis of this data was lost.  We reproduce it here.\n",
    "\n",
    "## Watermark\n",
    "\n",
    "Starting in the early 2010s, Matplotlib started including the bytes `b\"Matplotlib\"` in every PNG and PDF that they produce.  These bytes persist in the output PDFs stored on arXiv.  As a result, it's pretty simple to check if a PDF contains a Matplotlib image.  All we have to do is scan through every PDF and look for these bytes; no parsing required.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data is stored in a requester pays bucket at s3://arxiv (more information at https://arxiv.org/help/bulk_data_s3 ) and also on GCS hosted by Kaggle (more information at https://www.kaggle.com/datasets/Cornell-University/arxiv).  \n",
    "\n",
    "The data is about 1TB in size.  We're going to use Dask for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34748fc3-7f2f-442e-9829-626d88878234",
   "metadata": {},
   "source": [
    "## Create Dask Cluster\n",
    "\n",
    "We start with a small Dask cluster on AWS in the same region where the data is stored.  We also mimic the local software environment on the cluster with `package_sync=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c269a-c432-4352-aa01-0d9110b63304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    name=\"arxiv\",\n",
    "    shutdown_on_close=False,\n",
    "    package_sync=True, \n",
    "    backend_options={\"region\": \"us-east-1\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46591e5-664f-4bcc-98f3-c89bbb826331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, wait\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0965a0-fa87-470b-bd3d-0b5b7ecaca99",
   "metadata": {},
   "source": [
    "### Get all filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62539ef-5e91-43c5-afa8-0c3fa51b8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "s3 = s3fs.S3FileSystem(requester_pays=True)\n",
    "\n",
    "directories = s3.ls(\"s3://arxiv/pdf\")\n",
    "len(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc51124-c61e-4d7e-84ff-ffd551c7ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directories[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3219f-a6ce-487f-b5ae-522a7415c014",
   "metadata": {},
   "source": [
    "## Process one file\n",
    "\n",
    "Mostly we have to muck about with tar files.  This wasn't hard.  The `tarfile` library is in the stardard library.  It's not beautiful, but it's also not hard to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85146f13-5e5a-40e3-8d56-a79064f35ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import io\n",
    "\n",
    "def extract(filename):\n",
    "    out = []\n",
    "    with s3.open(filename) as f:\n",
    "        bytes = f.read()\n",
    "        with io.BytesIO() as bio:\n",
    "            bio.write(bytes)\n",
    "            bio.seek(0)\n",
    "            with tarfile.TarFile(fileobj=bio) as tf:\n",
    "                for member in tf.getmembers():\n",
    "                    if member.isfile() and member.name.endswith(\".pdf\"):\n",
    "                        data = tf.extractfile(member).read()\n",
    "                        out.append((\n",
    "                            member.name, \n",
    "                            b\"matplotlib\" in data.lower()\n",
    "                        ))\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de243ca8-bcd2-47b4-8574-bce3f0bda790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See an example of its use\n",
    "extract(directories[20])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feae86b-4c46-455d-8e5b-09eb80ec3400",
   "metadata": {},
   "source": [
    "# Scale function to full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dc6f5-2154-4241-a461-576c6733c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8f366-4cdf-4ac3-a0c1-08545f6e07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(extract, directories)\n",
    "wait(futures)\n",
    "\n",
    "# We had one error in one file.  Let's just ignore and move on.\n",
    "good = [future for future in futures if future.status == \"finished\"]\n",
    "\n",
    "lists = client.gather(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f61c10-b892-446f-bf5e-c504209b412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale down now that we're done\n",
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d74a56-e7c1-4614-86bd-6342e16d58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas\n",
    "\n",
    "dfs = [\n",
    "    pd.DataFrame(list, columns=[\"filename\", \"has_matplotlib\"]) \n",
    "    for list in lists\n",
    "]\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299b5097-ff28-4036-b569-a18449cca0d9",
   "metadata": {},
   "source": [
    "## Enrich Data\n",
    "\n",
    "Let's make a couple of functions to enhance our data a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c54e7-fc46-4180-9586-c06eac6432e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(filename):\n",
    "    year = int(filename.split(\"/\")[0][:2])\n",
    "    month = int(filename.split(\"/\")[0][2:4])\n",
    "    if year > 80:\n",
    "        year = 1900 + year\n",
    "    else:\n",
    "        year = 2000 + year\n",
    "    \n",
    "    return pd.Timestamp(year=year, month=month, day=1)\n",
    "\n",
    "date(\"0005/astro-ph0001322.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f8de5-c53a-49d9-8f8d-3ba62fcee727",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = df.filename.map(date)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64781f1-0486-4eda-81b4-68911383be7a",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "The scalable work is over.  Now we can just fool around with Pandas and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ae46c-ac65-48f1-a7ca-c6f742591c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"date\").has_matplotlib.mean().plot(\n",
    "    title=\"Matplotlib Usage in arXiv\", \n",
    "    ylabel=\"Fraction of papers\"\n",
    ").get_figure().savefig(\"results.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81198952-f6ba-4e1b-9792-36e54a5fe491",
   "metadata": {},
   "source": [
    "Yup.  Matplotlib is used pretty commonly on arXiv.  Go team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59d3a1d-289c-405c-8330-fc249e376b70",
   "metadata": {},
   "source": [
    "## Save results\n",
    "\n",
    "This data was slighly painful to procure.  Let's save the results locally for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0d6ff-4471-4a45-bbe1-6bcd8a8d72a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"arxiv-matplotlib.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623becf0-a84d-4cf7-b719-883bfe60eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs arxiv-matplotlib.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755b7a4-8b92-441c-9083-2bc0b51e2f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"arxiv-matplotlib.parquet\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc412d6-38b3-424e-8ca5-b4141d1b776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -hs arxiv-matplotlib.parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:play]",
   "language": "python",
   "name": "conda-env-play-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
